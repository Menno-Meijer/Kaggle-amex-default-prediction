{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "dcb2670b-869a-474d-b788-5c77bdbda89a",
    "_uuid": "ec0a3025-123f-4845-8547-11373afbdc3d",
    "execution": {
     "iopub.execute_input": "2022-08-03T05:39:16.538657Z",
     "iopub.status.busy": "2022-08-03T05:39:16.536602Z",
     "iopub.status.idle": "2022-08-03T05:39:18.012280Z",
     "shell.execute_reply": "2022-08-03T05:39:18.011313Z",
     "shell.execute_reply.started": "2022-08-03T05:39:16.536988Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "# import cudf \n",
    "#import torch\n",
    "#from numba import cuda\n",
    "#import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T05:39:18.014605Z",
     "iopub.status.busy": "2022-08-03T05:39:18.014117Z",
     "iopub.status.idle": "2022-08-03T05:39:18.019812Z",
     "shell.execute_reply": "2022-08-03T05:39:18.018858Z",
     "shell.execute_reply.started": "2022-08-03T05:39:18.014561Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 84 \n",
    "\n",
    "NAN_VALUE = -127\n",
    "\n",
    "#k-folds:\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T05:39:18.034022Z",
     "iopub.status.busy": "2022-08-03T05:39:18.033405Z",
     "iopub.status.idle": "2022-08-03T05:39:45.221473Z",
     "shell.execute_reply": "2022-08-03T05:39:45.220488Z",
     "shell.execute_reply.started": "2022-08-03T05:39:18.033987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 2077)\n",
      "CPU times: total: 31.1 s\n",
      "Wall time: 16.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_parquet(\"data_v29/train_processed.parquet\")\n",
    "train = train.sort_values(\"customer_ID\").reset_index(drop=True)\n",
    "print(train.shape)\n",
    "\n",
    "features = [col for col in train.columns if \"target\" not in col and \"customer_ID\" not in col]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AmEx metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T05:48:52.603049Z",
     "iopub.status.busy": "2022-08-03T05:48:52.602626Z",
     "iopub.status.idle": "2022-08-03T05:48:52.620281Z",
     "shell.execute_reply": "2022-08-03T05:48:52.619325Z",
     "shell.execute_reply.started": "2022-08-03T05:48:52.603006Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "# https://www.kaggle.com/code/rohanrao/amex-competition-metric-implementations\n",
    "\n",
    "def amex_metric_numpy(y_true: np.array, y_pred: np.array) -> float:\n",
    "\n",
    "    # count of positives and negatives\n",
    "    n_pos = y_true.sum()\n",
    "    n_neg = y_true.shape[0] - n_pos\n",
    "\n",
    "    # sorting by descring prediction values\n",
    "    indices = np.argsort(y_pred)[::-1]\n",
    "    preds, target = y_pred[indices], y_true[indices]\n",
    "\n",
    "    # filter the top 4% by cumulative row weights\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_filter = cum_norm_weight <= 0.04\n",
    "\n",
    "    # default rate captured at 4%\n",
    "    d = target[four_pct_filter].sum() / n_pos\n",
    "\n",
    "    # weighted gini coefficient\n",
    "    lorentz = (target / n_pos).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    # max weighted gini coefficient\n",
    "    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n",
    "\n",
    "    # normalized weighted gini coefficient\n",
    "    g = gini / gini_max\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "\n",
    "def amex_metric(y_true, y_pred):\n",
    "#     @MARTIN KOVACEVIC BUVINIC  ; https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return \"amex_metric\", amex_metric(y_true, y_pred), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T05:48:52.621845Z",
     "iopub.status.busy": "2022-08-03T05:48:52.621507Z",
     "iopub.status.idle": "2022-08-03T05:48:52.634564Z",
     "shell.execute_reply": "2022-08-03T05:48:52.633837Z",
     "shell.execute_reply.started": "2022-08-03T05:48:52.621815Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set model parameters:\n",
    "       \n",
    "\n",
    "LGBM_parameters = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\":\"auc\", #\"binary_logloss\",\n",
    "    \"boosting\": \"dart\",\n",
    "    \"seed\": RANDOM_STATE,\n",
    "    \"num_leaves\":100,\n",
    "    \"learning_rate\":0.01,\n",
    "    \"feature_fraction\": 0.2,\n",
    "    \"bagging_freq\":10,\n",
    "    \"bagging_fraction\":0.5,\n",
    "    \"lambda_l2\":2,\n",
    "    \"min_data_in_leaf\": 40,\n",
    "#     \"max_bin\":63,\n",
    "    \"n_jobs\":-1,\n",
    "#     \"device\":\"gpu\",\n",
    "#     \"gpu_platform_id\":0,\n",
    "#     \"gpu_device_id\": 0,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T05:48:52.636655Z",
     "iopub.status.busy": "2022-08-03T05:48:52.636236Z",
     "iopub.status.idle": "2022-08-03T05:48:52.860954Z",
     "shell.execute_reply": "2022-08-03T05:48:52.859953Z",
     "shell.execute_reply.started": "2022-08-03T05:48:52.636613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T05:48:52.864361Z",
     "iopub.status.busy": "2022-08-03T05:48:52.863855Z",
     "iopub.status.idle": "2022-08-03T05:48:52.870759Z",
     "shell.execute_reply": "2022-08-03T05:48:52.869847Z",
     "shell.execute_reply.started": "2022-08-03T05:48:52.864316Z"
    }
   },
   "outputs": [],
   "source": [
    "original_cat_col = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "cat_col = [col + \"_last\" for col in original_cat_col]\n",
    "cat_col += [col + \"_2ndlast\" for col in original_cat_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T05:48:52.872241Z",
     "iopub.status.busy": "2022-08-03T05:48:52.871913Z",
     "iopub.status.idle": "2022-08-03T05:48:55.505266Z",
     "shell.execute_reply": "2022-08-03T05:48:55.504371Z",
     "shell.execute_reply.started": "2022-08-03T05:48:52.872210Z"
    }
   },
   "outputs": [],
   "source": [
    "train[cat_col] = train[cat_col].replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_amex(estimator, X, y):\n",
    "#     y_score = estimator.predict(X)  # You could also use the binary predict, but probabilities should give you a more realistic score.\n",
    "#     return roc_auc_score(y, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reporting util for different optimizers\n",
    "# def report_perf(optimizer, X, y, title=\"model\", callbacks=None):\n",
    "#     \"\"\"\n",
    "#     A wrapper for measuring time and performances of different optmizers\n",
    "    \n",
    "#     optimizer = a sklearn or a skopt optimizer\n",
    "#     X = the training set \n",
    "#     y = our target\n",
    "#     title = a string label for the experiment\n",
    "#     \"\"\"\n",
    "#     start = time()\n",
    "    \n",
    "#     if callbacks is not None:\n",
    "#         optimizer.fit(X, y, callback=callbacks)\n",
    "#     else:\n",
    "#         optimizer.fit(X, y)\n",
    "        \n",
    "#     d=pd.DataFrame(optimizer.cv_results_)\n",
    "#     best_score = optimizer.best_score_\n",
    "#     best_score_std = d.iloc[optimizer.best_index_].std_test_score\n",
    "#     best_params = optimizer.best_params_\n",
    "    \n",
    "#     print((title + \" took %.2f seconds,  candidates checked: %d, best CV score: %.3f \"\n",
    "#            + u\"\\u00B1\"+\" %.3f\") % (time() - start, \n",
    "#                                    len(optimizer.cv_results_['params']),\n",
    "#                                    best_score,\n",
    "#                                    best_score_std))    \n",
    "#     print(f\"Best parameters:{best_params}\")\n",
    "    \n",
    "#     return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# import xgboost\n",
    "# import lightgbm as lgb\n",
    "# from skopt import BayesSearchCV\n",
    "# from skopt.callbacks import DeadlineStopper, DeltaYStopper\n",
    "# from skopt.space import Real, Categorical, Integer\n",
    "# from sklearn.metrics import auc\n",
    "# from sklearn.metrics import make_scorer\n",
    "# # the kaggle book\n",
    "# #https://www.kaggle.com/code/lucamassaron/scikit-optimize-for-lightgbm\n",
    "\n",
    "\n",
    "# scorer = make_scorer(auc, greater_is_better=True, needs_threshold=True)\n",
    "# params = {\n",
    "#         \"learning_rate\": [0.01],\n",
    "#         \"n_estimators\":[2500],\n",
    "#         \"max_depth\":Integer(1,16), #int 1-16\n",
    "#         \"num_leaves\": Integer(2,512),#int between 2 and 2^max_depth\n",
    "#         \"min_data_in_leaf\": Integer(0,300), # int 0-300\n",
    "#     #     \"min_gain_to_split\": , # float 0-15; avoid unnecessary tree splits and reduce overfitting\n",
    "#         \"max_bin\": Integer(32,512), # int between 32 and 512; larger than default 255 risk of overfitting\n",
    "#         \"subsample\": Real(0.01, 1.0, \"uniform\"), # real number between 0.01 and 1.0; portion of sample be used\n",
    "#         \"subsample_freq\":Integer(0,10), # int between 0-10\n",
    "#         \"feature_fraction\":Real(0.01, 1.0, \"uniform\"), # real between 0.1 and 1.0; features to be subsampled\n",
    "#     #     \"subsample_for_bin\": Integer(30,1000000),# int 30 and number of samples\n",
    "#         \"reg_lambda\":Real(1e-9, 100.0, \"log-uniform\"), # real number 0 and 100.0, log-uniform; L2\n",
    "#         \"reg_alpha\": Real(1e-9, 100.0, \"log-uniform\"), #real number 0 and 100.0, log-uniform;l1\n",
    "#         \"scale_pos_weight\": Real(1e-9, 500.0, \"log-uniform\"),# real 1e-6 and 500 log uniform; weights the pos against neg cases\n",
    "#         }\n",
    "# skf = StratifiedKFold(n_splits=FOLDS, shuffle = True, random_state = RANDOM_STATE)\n",
    "# lgbm = lgb.LGBMClassifier(boosting_type=\"gbdt\",\n",
    "#                           metric=\"auc\",\n",
    "#                           objective=\"binary\",\n",
    "#                           random_state = RANDOM_STATE,\n",
    "#                           n_jobs=-1,\n",
    "#                           verbose=-1\n",
    "#                        )\n",
    "# BayesSearch = BayesSearchCV(estimator=lgbm,\n",
    "#                             search_spaces=params,\n",
    "# #                             scoring=scorer,\n",
    "#                               n_iter=60,\n",
    "# #                             n_points= 3, #number of hyperparameters evaluated at each time\n",
    "#                               n_jobs=1,\n",
    "# #                             iid=False,\n",
    "#                             return_train_score=False,\n",
    "#                             refit=False,\n",
    "#                             optimizer_kwargs={\"base_estimator\":\"GP\"},\n",
    "#                               cv=skf,\n",
    "#                               verbose=2, random_state=RANDOM_STATE )\n",
    "\n",
    "# deltaY = DeltaYStopper(delta=0.0001)\n",
    "# time_limit = DeadlineStopper(total_time=60*60*12)\n",
    "\n",
    "# best_params = report_perf(BayesSearch, X, y, \"lgbm\", callbacks=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T05:48:55.515063Z",
     "iopub.status.busy": "2022-08-03T05:48:55.514400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fold 0\n",
      "lgb: fold:0, acc: 0.7963036426118163\n",
      "starting fold 1\n",
      "lgb: fold:1, acc: 0.7968672158469023\n",
      "starting fold 2\n",
      "lgb: fold:2, acc: 0.7983153352077621\n",
      "starting fold 3\n",
      "lgb: fold:3, acc: 0.7965792770116737\n",
      "starting fold 4\n",
      "lgb: fold:4, acc: 0.7978565809797978\n",
      "LGB: mean: 0.7971844103315904\n",
      "LGB: Acc over full dataset: 0.7971333793398161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "acc_list_lgb = []\n",
    "y_val_full_lgb = []\n",
    "y_pred_full_lgb = []\n",
    "customer_id_list = []\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(train[features], train[\"target\"])):\n",
    "#     if fold != 4:\n",
    "#         continue\n",
    "\n",
    "    if fold == 0:\n",
    "        boost_rounds = 10900\n",
    "    elif fold == 1:\n",
    "        boost_rounds = 11100\n",
    "    elif fold == 2:\n",
    "        boost_rounds = 8000\n",
    "    elif fold == 3:\n",
    "        boost_rounds = 14600\n",
    "    elif fold == 4:\n",
    "        boost_rounds = 10800\n",
    "        \n",
    "    print(f\"starting fold {fold}\")\n",
    "    \n",
    "    ######\n",
    "    x_train_fold, x_val_fold = train[features].iloc[train_index], train[features].iloc[val_index]\n",
    "    y_train_fold, y_val_fold = train[\"target\"].iloc[train_index], train[\"target\"].iloc[val_index]\n",
    "    \n",
    "    #### LGBM:\n",
    "    \n",
    "    train_lgb = lgb.Dataset(x_train_fold, y_train_fold, categorical_feature = cat_col)\n",
    "    val_lgb = lgb.Dataset(x_val_fold, y_val_fold, categorical_feature = cat_col)\n",
    "    \n",
    "    \n",
    "    \n",
    "    del x_train_fold,y_train_fold\n",
    "    gc.collect()\n",
    "    lgb_model = lgb.train(\n",
    "                        params = LGBM_parameters,\n",
    "                        train_set = train_lgb,\n",
    "                        num_boost_round = boost_rounds,\n",
    "                        valid_sets = [train_lgb, val_lgb],\n",
    "                        callbacks=[lgb.early_stopping(1500)],\n",
    "                        verbose_eval = 50,\n",
    "                        feval = lgb_amex_metric\n",
    "                        )\n",
    "    # Save best model\n",
    "    del train_lgb, val_lgb\n",
    "    gc.collect()\n",
    "    joblib.dump(lgb_model, f\"results/lgbm_fold{fold}_seed{RANDOM_STATE}.pkl\")\n",
    "    print(\"model saved\")\n",
    "\n",
    "\n",
    "\n",
    "    ### for OOF: ####\n",
    "#     lgb_model = joblib.load(f\"/results/lgbm_fold{fold}_seed{RANDOM_STATE}.pkl\")\n",
    "\n",
    "    #################\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_pred_lgb = lgb_model.predict(x_val_fold)\n",
    "    acc_lgb = amex_metric_numpy(y_val_fold.values, y_pred_lgb)\n",
    "    \n",
    "    \n",
    "    \n",
    "    acc_list_lgb.append(acc_lgb)\n",
    "    y_val_full_lgb.append(y_val_fold.to_numpy().ravel()) # acc over full dataset\n",
    "\n",
    "    y_pred_full_lgb.append(y_pred_lgb)\n",
    "    customer_id_list.append(train[\"customer_ID\"].iloc[val_index])\n",
    "    \n",
    "    print(f\"lgb: fold:{fold}, acc: {acc_lgb}\")\n",
    "    \n",
    "        \n",
    "    # Save best model\n",
    "    del lgb_model, y_pred_lgb, acc_lgb, y_val_fold, x_val_fold\n",
    "    gc.collect()\n",
    "    #########\n",
    "    \n",
    "\n",
    "# lgb:\n",
    "print(f\"LGB: mean: {np.mean(acc_list_lgb)}\")\n",
    "\n",
    "\n",
    "# lgb\n",
    "y_val_full_array_lgb = np.concatenate(y_val_full_lgb, axis=None)\n",
    "y_pred_full_array_lgb = np.concatenate(y_pred_full_lgb, axis=None)\n",
    "acc_full_lgb = amex_metric_numpy(y_val_full_array_lgb,y_pred_full_array_lgb)\n",
    "print(f\"LGB: Acc over full dataset: {acc_full_lgb}\")\n",
    "customer_id_list_conc = np.concatenate(customer_id_list, axis=None)\n",
    "df_OOF = pd.DataFrame()\n",
    "df_OOF[\"customer_ID\"] = pd.Series(customer_id_list_conc)\n",
    "df_OOF[\"prediction\"] = pd.Series(y_pred_full_array_lgb)\n",
    "del y_val_full_array_lgb, y_pred_full_array_lgb,acc_full_lgb, acc_list_lgb\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9223189665817919541</td>\n",
       "      <td>0.001138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9223188534444851899</td>\n",
       "      <td>0.018665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9222977106653703082</td>\n",
       "      <td>0.648444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9222795947410574988</td>\n",
       "      <td>0.990211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9222571608979063563</td>\n",
       "      <td>0.759488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458908</th>\n",
       "      <td>9222830459409282183</td>\n",
       "      <td>0.006317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458909</th>\n",
       "      <td>9222865474092465587</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458910</th>\n",
       "      <td>9222877733476602020</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458911</th>\n",
       "      <td>9223073742590486866</td>\n",
       "      <td>0.000684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458912</th>\n",
       "      <td>9223345210145379887</td>\n",
       "      <td>0.002591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458913 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                customer_ID  prediction\n",
       "0      -9223189665817919541    0.001138\n",
       "1      -9223188534444851899    0.018665\n",
       "2      -9222977106653703082    0.648444\n",
       "3      -9222795947410574988    0.990211\n",
       "4      -9222571608979063563    0.759488\n",
       "...                     ...         ...\n",
       "458908  9222830459409282183    0.006317\n",
       "458909  9222865474092465587    0.000369\n",
       "458910  9222877733476602020    0.000066\n",
       "458911  9223073742590486866    0.000684\n",
       "458912  9223345210145379887    0.002591\n",
       "\n",
       "[458913 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OOF.to_csv(f\"LGBM_DART-V3_data29_seed{RANDOM_STATE}_OOF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on dataV29: DART-V3\n",
    "#fold 0; n_esti: 10900; best amex: 0.796504\n",
    "#fold 1; n_esti: 11100; best amex: 0.798133\n",
    "#fold 2; n_esti: 8000; best amex: 0.798726 \n",
    "#fold 3; n_esti: 14600; best amex: 0.797246 \n",
    "#fold 4; n_esti: 10800; best amex: 0.799269\n",
    "# mean: 0.7979756 OOF: 0.7972244432729978\n",
    "######################\n",
    "# on data 32: DART-V4\n",
    "# 15000: [0.7943137890316092,0.7964981155279881]\n",
    "#fold 0; n_esti:13900 ; best amex: 0.795729\n",
    "#fold 1; n_esti: 8150; best amex: 0.798049\n",
    "#fold 2; n_esti:13500 ; best amex: 0.798215\n",
    "#fold 3; n_esti:8450 ; best amex:  0.795595 \n",
    "#fold 4; n_esti: 7650; best amex: 0.798923 \n",
    "# mean:0.7973020241502867 oof: 0.7966134974634839\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear GPU memory\n",
    "# torch.cuda.empty_cache()\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "# cuda.select_device(0)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "chunks = 8\n",
    "test_rows = 924621\n",
    "\n",
    "test_submission = pd.DataFrame()\n",
    "pseudo_test_df = pd.DataFrame()\n",
    "for chunk in range(chunks):\n",
    "\n",
    "    print(f\"chunk:{chunk+1}\")\n",
    "    test = pd.read_parquet(f\"data_v29/test_processed_chunk{chunk}.parquet\")\n",
    "#     test = test.sort_values([\"customer_ID\",\"S_2\"])\n",
    "#     test = test.reset_index(drop=True)\n",
    "    print(f\"Loaded chunk#{chunk+1}\")\n",
    "    \n",
    "    gc.collect()\n",
    "    test_submission_chunk = pd.DataFrame()\n",
    "    test_submission_chunk[\"customer_ID\"] = test[\"customer_ID\"]\n",
    "    test = test.drop(columns=[\"customer_ID\"])\n",
    "    test[cat_col] = test[cat_col].replace(-1, np.nan)\n",
    "    \n",
    "    #LGBM:\n",
    "    \n",
    "    predictions_lgb = []\n",
    "    print(\"Starting predictions LGBM:\")\n",
    "    for fold in range(FOLDS):\n",
    "        \n",
    "        lgb_model_loaded = joblib.load(f\"results/lgbm_fold{fold}_seed{RANDOM_STATE}.pkl\")\n",
    "        \n",
    "        test_pred_lgb = lgb_model_loaded.predict(test)\n",
    "        predictions_lgb.append(test_pred_lgb)\n",
    "        \n",
    "        print(f\"prediction added for fold:{fold}\")\n",
    "        del lgb_model_loaded, test_pred_lgb\n",
    "        gc.collect()\n",
    "    mean_predictions_lgb = np.mean(np.column_stack(predictions_lgb), axis=1)\n",
    "    std_predictions_lgb = np.std(np.column_stack(predictions_lgb), axis=1)\n",
    "    test_submission_chunk[\"prediction\"] = mean_predictions_lgb\n",
    "    test_submission_chunk[\"std\"] = std_predictions_lgb\n",
    "    test_submission_chunk[\"chunk\"] = chunk\n",
    "    test_submission = test_submission.append(test_submission_chunk)\n",
    "    del test_submission_chunk\n",
    "    \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "print(\"Finished predicting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.std(np.column_stack(predictions_lgb), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission = test_submission.drop(columns=[\"std\",\"chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission.to_csv(\"submission_dart_V3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
